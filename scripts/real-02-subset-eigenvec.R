library(optparse)
library(readr)

# this script takes the max PCs file and creates all the subsets efficiently, for GCTA to include as covariates
# this is way faster than having GCTA create each file independently (i.e. recalculating the eigendecomposition each time).
# NOTE: a second file, with my version of PCA, is ignored here (easier to test in R instead of here)

# number of PCs to explore
n_pcs_max <- 90
# the name is for dir only, actual file is just "data"
name_in <- 'data'

############
### ARGV ###
############

# define options
option_list = list(
    make_option("--bfile", type = "character", default = NA, 
                help = "Base name for input plink files (.BED/BIM/FAM)", metavar = "character"),
    make_option("--plink", action = "store_true", default = FALSE, 
                help = "Process 'plink2' estimates, instead of GCTA's"),
    make_option("--clean", action = "store_true", default = FALSE, 
                help = "remove redundant files generated by this script"),
    make_option("--dcc", action = "store_true", default = FALSE, 
                help = "Duke Compute Cluster runs (alters paths only)")
)

opt_parser <- OptionParser(option_list = option_list)
opt <- parse_args(opt_parser)

# get values
name <- opt$bfile

# only plink2 estimates have columns
col_names <- FALSE

# this is the only change needed to work with "plink" estimates
if ( opt$plink ) {
    name_in <- 'data-plink'
    col_names <- TRUE
}

# stop if name is missing
if ( is.na(name) )
    stop('`--bfile` terminal option is required!')

# move to where the data is
if ( opt$dcc ) {
    # on DCC we go here, no name for simplicity (data is only temporarily there, so I won't have more than one dataset there at the time)
    setwd( '/work/ao128/' )
} else {
    setwd( '../data/' )
}
setwd( name )

# function that returns file path of interest
file_eigenvec <- function( name, n_pcs ) {
    paste0( name, '-n_pcs_', n_pcs, '.eigenvec' )
}

if ( opt$clean ) {
    # remove all derivative files
    # quick move, no sanity checks... (no loss here really)
    for ( n_pcs in 1 : (n_pcs_max - 1 ) )
        file.remove(
            file_eigenvec( name_in, n_pcs )
        )
} else {
    # read the original file
    tib <- read_table(
        file_eigenvec( name_in, n_pcs_max ),
        col_names = col_names
    )
    # now navigate PCs in output, backwards so subsetting makes sense
    for ( n_pcs in (n_pcs_max - 1 ) : 1 ) {
        # remove the previous column (shifted by 2 because of FAM and ID columns)
        tib <- tib[ , -( n_pcs + 3 ) ]
        # make sure number of columns is as expected
        # +2 because of FAM and ID columns in the beginning
        stopifnot(
            ncol( tib ) == n_pcs + 2 
        )
        # write output, in the same format as before!
        write_tsv(
            tib,
            file_eigenvec( name_in, n_pcs ),
            col_names = col_names
        )
    }
}
